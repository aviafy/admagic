# Gemini Flow Debugging Guide

## Overview

This document explains the comprehensive logging added to debug the Gemini provider selection issue. The logs trace the entire flow from frontend to backend to identify where OpenAI might still be used when Gemini is selected.

## Problem Statement

User reports that when they switch to Gemini in the UI, the system still uses OpenAI for content moderation.

## Log Flow

### Frontend Logs

#### 1. **LLM Provider Context Initialization**

```
ğŸ“‚ [LLMProvider] Loading provider from localStorage: <value or "not found">
âœ… [LLMProvider] Provider set to: <provider>
â„¹ï¸ [LLMProvider] Using default provider: openai
```

**Location**: `frontend/src/shared/contexts/LLMProviderContext.tsx` (lines 22-30)
**When**: On application load
**What to check**: Verify the correct provider is loaded from localStorage

#### 2. **Provider Switch**

```
ğŸ”„ [LLMProvider] Switching provider from <old> to <new>
âœ… [LLMProvider] Provider saved to localStorage: <provider>
```

**Location**: `frontend/src/shared/contexts/LLMProviderContext.tsx` (lines 34-38)
**When**: User clicks OpenAI or Gemini button in header
**What to check**: Confirm provider change is persisted to localStorage

#### 3. **User Click Events**

```
ğŸ–±ï¸ [Header] User clicked OpenAI button
ğŸ–±ï¸ [Header] User clicked Gemini button
```

**Location**: `frontend/src/shared/components/Header.tsx` (lines 84, 101)
**When**: User clicks provider toggle buttons
**What to check**: Verify button clicks are registered

#### 4. **Content Submission**

```
ğŸš€ [Frontend] Submitting content with AI provider: <provider>
âœ… [Frontend] Submission response received: <response>
```

**Location**: `frontend/src/features/content/components/CreatePostCard.tsx` (lines 332, 339)
**When**: User submits content for moderation
**What to check**: Confirm the correct provider is being sent in the request

---

### Backend Logs

#### 5. **Controller - Request Received**

```
ğŸ”µ [Controller] Received content submission from user: <userId> with AI provider: <provider or "default">
ğŸ“¦ [Controller] SubmitDto: <JSON payload>
```

**Location**: `backend/src/modules/content/content.controller.ts` (lines 45-48)
**When**: Backend receives content submission
**What to check**: Verify the `aiProvider` field is present in the DTO

#### 6. **Content Service - Processing**

```
ğŸŸ¢ [ContentService] Processing moderation for submission: <submissionId>
ğŸ¤– [ContentService] Requested AI provider: <provider or "default (OpenAI)">
ğŸ“¤ [ContentService] Calling moderationService with provider: <provider>
ğŸ“¥ [ContentService] Moderation result received - Decision: <decision>, Used provider: <provider>
```

**Location**: `backend/src/modules/content/content.service.ts` (lines 62-76)
**When**: Content service processes the submission
**What to check**: Confirm provider is passed correctly to moderation service

#### 7. **Moderation Service - Agent Selection**

```
ğŸŸ£ [ModerationService] Moderating <contentType> content with provider: <provider or "default (OpenAI)">
ğŸ’¾ [ModerationService] Using cached moderation result (saved AI API call) - Used provider: <provider>
ğŸ”§ [ModerationService] No cache hit. Creating/using agent with provider: <provider>
âš¡ [ModerationService] Creating NEW agent instance for provider: <provider>
âœ… [ModerationService] New agent created with preferred provider: <provider>
â™»ï¸ [ModerationService] Using existing default agent (OpenAI)
ğŸš€ [ModerationService] Calling agent.moderate()...
âœ… [ModerationService] Agent returned result with provider: <provider>
```

**Location**: `backend/src/modules/moderation/moderation.service.ts` (lines 54-84)
**When**: Moderation service decides which agent to use
**What to check**:

- If Gemini is requested, verify a new agent is created
- Check if cache is being used (could be serving OpenAI cached result)
- **CRITICAL**: Verify the cache key includes the provider (line 58)

#### 8. **Moderation Agent - Initialization**

```
ğŸ—ï¸ [ModerationAgent] Constructor called with preferredProvider: <provider>
âœ… [ModerationAgent] Gemini AI initialized
âš ï¸ [ModerationAgent] Gemini API key not provided, using OpenAI only
ğŸ”§ [ModerationAgent] Initializing services with preferredProvider: <provider>
âœ… [ModerationAgent] Moderation agent initialized with preferred provider: <provider>
```

**Location**: `backend/src/modules/moderation/agents/moderation.agent.ts` (lines 37-74)
**When**: A new moderation agent is created
**What to check**:

- Confirm Gemini API key is available
- Verify services are initialized with correct provider

#### 9. **Moderation Agent - Analysis Node**

```
ğŸ“Š [ModerationAgent.analyzeNode] Analyzing <contentType> content
ğŸ‘ï¸ [ModerationAgent.analyzeNode] Using Vision Model for image
âœ… [ModerationAgent.analyzeNode] Vision analysis complete - Using OpenAI
âš ï¸ [ModerationAgent.analyzeNode] Vision analysis failed, falling back to text analysis
ğŸ¤– [ModerationAgent.analyzeNode] Calling ContentAnalyzer.analyze()...
âœ… [ModerationAgent.analyzeNode] Analysis complete with provider: <provider>
```

**Location**: `backend/src/modules/moderation/agents/moderation.agent.ts` (lines 118-149)
**When**: Content is analyzed
**What to check**:

- For images, vision analysis always uses OpenAI (expected behavior)
- For text, verify ContentAnalyzer is called

#### 10. **Content Analyzer - Provider Selection**

```
ğŸ”§ [ContentAnalyzer] Initialized with preferredProvider: <provider>, Gemini available: <true/false>
ğŸ” [ContentAnalyzer.analyze] Starting analysis with preferredProvider: <provider>
ğŸ“ [ContentAnalyzer.analyze] Gemini available: <true/false>
ğŸŸ¢ [ContentAnalyzer.analyze] Preferred provider is GEMINI, attempting Gemini analysis...
âœ… [ContentAnalyzer.analyze] Successfully used Gemini for analysis
âŒ [ContentAnalyzer.analyze] Gemini failed, falling back to OpenAI. Error: <error>
âœ… [ContentAnalyzer.analyze] Fallback to OpenAI successful
ğŸ”µ [ContentAnalyzer.analyze] Preferred provider is OPENAI or Gemini unavailable, using OpenAI...
âœ… [ContentAnalyzer.analyze] Successfully used OpenAI for analysis
âš ï¸ [ContentAnalyzer.analyze] OpenAI failed, falling back to Gemini
âœ… [ContentAnalyzer.analyze] Fallback to Gemini successful
```

**Location**: `backend/src/modules/moderation/services/content-analyzer.service.ts` (lines 19-71)
**When**: Text content is analyzed
**What to check**:

- Verify preferred provider matches request
- If Gemini fails, check error message
- Confirm correct provider is actually used

---

## Debugging Steps

### Step 1: Check Frontend Provider State

1. Open browser DevTools Console
2. Look for `ğŸ“‚ [LLMProvider] Loading provider from localStorage:`
3. Verify the loaded provider is correct
4. If not, check localStorage: `localStorage.getItem('admagic-ai-provider')`

### Step 2: Switch Providers

1. Click Gemini button in header
2. Look for: `ğŸ–±ï¸ [Header] User clicked Gemini button`
3. Then: `ğŸ”„ [LLMProvider] Switching provider from openai to gemini`
4. Then: `âœ… [LLMProvider] Provider saved to localStorage: gemini`

### Step 3: Submit Content

1. Submit a text post
2. Frontend logs should show:
   ```
   ğŸš€ [Frontend] Submitting content with AI provider: gemini
   ```
3. Backend controller should receive:
   ```
   ğŸ”µ [Controller] Received content submission from user: <id> with AI provider: gemini
   ```

### Step 4: Check Backend Processing

1. Check if cache is hit:

   ```
   ğŸ’¾ [ModerationService] Using cached moderation result
   ```

   - **If cached**: This might be the problem! Cache key should include provider
   - **Solution**: Clear cache or ensure cache key includes provider (line 58 in moderation.service.ts)

2. Check agent creation:

   ```
   âš¡ [ModerationService] Creating NEW agent instance for provider: gemini
   âœ… [ModerationAgent] Constructor called with preferredProvider: gemini
   ```

3. Check Gemini initialization:

   ```
   âœ… [ModerationAgent] Gemini AI initialized
   ```

   - **If you see** `âš ï¸ Gemini API key not provided`: Check `.env` for `GEMINI_API_KEY`

4. Check actual analysis:
   ```
   ğŸŸ¢ [ContentAnalyzer.analyze] Preferred provider is GEMINI, attempting Gemini analysis...
   âœ… [ContentAnalyzer.analyze] Successfully used Gemini for analysis
   ```
   - **If you see fallback**: Check the error message for why Gemini failed

### Step 5: Verify Result

1. Final log should show:
   ```
   âœ… [ModerationService] Agent returned result with provider: gemini
   ```
2. This confirms Gemini was actually used

---

## Common Issues and Solutions

### Issue 1: Cache Hit with Wrong Provider

**Symptom**:

```
ğŸ’¾ [ModerationService] Using cached moderation result - Used provider: openai
```

When you requested Gemini.

**Root Cause**: The cache key includes the provider, but you might be testing the same content.

**Solution**:

- Test with different content
- Or clear the cache by restarting the backend
- The cache key is: `${content}:${provider}` (line 58)

### Issue 2: Gemini API Key Missing

**Symptom**:

```
âš ï¸ [ModerationAgent] Gemini API key not provided, using OpenAI only
```

**Solution**:

1. Check `backend/.env` for `GEMINI_API_KEY`
2. Restart backend server
3. Look for startup log: `âœ… Gemini AI initialized`

### Issue 3: Gemini Request Fails

**Symptom**:

```
âŒ [ContentAnalyzer.analyze] Gemini failed, falling back to OpenAI. Error: <error>
```

**Solution**:

- Check error message for specific issue (API key, quota, network, etc.)
- Verify Gemini API key is valid
- Check if content violates Gemini's safety filters

### Issue 4: Provider Not Sent from Frontend

**Symptom**:

```
ğŸ”µ [Controller] Received content submission from user: <id> with AI provider: default
```

**Solution**:

- Check if LLMProviderContext is properly wrapped around the app
- Verify `useLLMProvider()` hook is working
- Check browser localStorage for the provider value

---

## Testing Checklist

- [ ] Provider loads correctly on app start
- [ ] Can switch between OpenAI and Gemini
- [ ] Provider persists in localStorage
- [ ] Correct provider is sent in submission request
- [ ] Backend receives correct provider
- [ ] New agent is created for Gemini (when not using default OpenAI)
- [ ] Gemini API key is initialized
- [ ] ContentAnalyzer attempts to use Gemini
- [ ] Result shows correct provider was used
- [ ] Cache respects provider preference

---

## Log Interpretation Example

### Successful Gemini Flow:

```
ğŸ“‚ [LLMProvider] Loading provider from localStorage: gemini
âœ… [LLMProvider] Provider set to: gemini
ğŸš€ [Frontend] Submitting content with AI provider: gemini
ğŸ”µ [Controller] Received content submission from user: xyz with AI provider: gemini
ğŸŸ¢ [ContentService] Requested AI provider: gemini
ğŸŸ£ [ModerationService] Moderating text content with provider: gemini
âš¡ [ModerationService] Creating NEW agent instance for provider: gemini
ğŸ—ï¸ [ModerationAgent] Constructor called with preferredProvider: gemini
âœ… [ModerationAgent] Gemini AI initialized
ğŸ”§ [ContentAnalyzer] Initialized with preferredProvider: gemini, Gemini available: true
ğŸ” [ContentAnalyzer.analyze] Starting analysis with preferredProvider: gemini
ğŸŸ¢ [ContentAnalyzer.analyze] Preferred provider is GEMINI, attempting Gemini analysis...
âœ… [ContentAnalyzer.analyze] Successfully used Gemini for analysis
âœ… [ModerationService] Agent returned result with provider: gemini
```

### Issue: Cache Hit with OpenAI:

```
ğŸ“‚ [LLMProvider] Loading provider from localStorage: gemini
âœ… [LLMProvider] Provider set to: gemini
ğŸš€ [Frontend] Submitting content with AI provider: gemini
ğŸ”µ [Controller] Received content submission from user: xyz with AI provider: gemini
ğŸŸ¢ [ContentService] Requested AI provider: gemini
ğŸŸ£ [ModerationService] Moderating text content with provider: gemini
ğŸ’¾ [ModerationService] Using cached moderation result - Used provider: openai
```

**Problem**: Content was previously cached with OpenAI. Try different content!

---

## Environment Variables

Make sure these are set in `backend/.env`:

```bash
OPENAI_API_KEY=sk-...
GEMINI_API_KEY=...
```

---

## Quick Debug Command

To see all logs in real-time, run backend with:

```bash
cd backend
npm run start:dev
```

Then watch the logs as you:

1. Switch to Gemini in UI
2. Submit content
3. Follow the log flow above

---

## Contact

If the issue persists after following this guide:

1. Copy all relevant logs from the flow
2. Note where the flow deviates from expected
3. Check the specific service where the issue occurs
4. Review the code at that location
